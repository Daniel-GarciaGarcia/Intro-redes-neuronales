{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mi primera red (MNIST,  clasificación de números con TensorFlow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mnist_sample.png\" style=\"width:30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estamos usando TensorFlow  1.13.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "print('Estamos usando TensorFlow ', tf.__version__)\n",
    "\n",
    "import sys\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib_utils\n",
    "from importlib import reload\n",
    "reload(matplotlib_utils)\n",
    "\n",
    "import keras_utils\n",
    "from keras_utils import reset_tf_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos\n",
    "\n",
    "Tenemos 50000 imágenes de 28x28 píxeles de números, del 0 al 9.\n",
    "Se entrenará un clasificador para estos datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessed_mnist\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = preprocessed_mnist.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train [dimensiones (50000, 28, 28)],  muestra:\n",
      " [[0.         0.29803922 0.96470588 0.98823529 0.43921569]\n",
      " [0.         0.33333333 0.98823529 0.90196078 0.09803922]\n",
      " [0.         0.33333333 0.98823529 0.8745098  0.        ]\n",
      " [0.         0.33333333 0.98823529 0.56862745 0.        ]\n",
      " [0.         0.3372549  0.99215686 0.88235294 0.        ]]\n",
      "\n",
      "Plot de la muestra:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Un número completo\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train [dimensiones (50000,)] 10 muestras:\n",
      " [5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "# X contiene valores en rgb, divididos entre 255 (normalizacion)\n",
    "print('X_train [dimensiones %s],  muestra:\\n' % (str(X_train.shape)), X_train[1, 15:20, 5:10])\n",
    "print('\\nPlot de la muestra:')\n",
    "plt.imshow(X_train[1, 15:20, 5:10], cmap='Greys')\n",
    "plt.show();\n",
    "print('\\nUn número completo')\n",
    "plt.imshow(X_train[1], cmap='Greys')\n",
    "plt.show()\n",
    "print('y_train [dimensiones %s] 10 muestras:\\n' % (str(y_train.shape)), y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo lineal\n",
    "\n",
    "La tarea es entrenar un clasificador lineal $\\vec{x} \\rightarrow y$ con SGD usando TensorFlow.\n",
    "\n",
    "Necesitamos calcular una transformación lineal  $z_k$ para cada clase: \n",
    "$$z_k = \\vec{x} \\cdot \\vec{w_k} + b_k \\quad;k = 0..9$$\n",
    "\n",
    "Y transformar $z_k$ a probabilidades $p_k$ con softmax (regresión logistica): \n",
    "$$p_k = \\frac{e^{z_k}}{\\sum_{i=0}^{9}{e^{z_i}}} \\quad;k = 0..9$$\n",
    "\n",
    "Como función de pérdida de usará la entropía cruzada (cross-entropy) para entrenar el clasificador multiclase:\n",
    "$$\\text{entropía cruzada}(y, p) = -\\sum_{k=0}^{9}{\\log(p_k)[y = k]}$$ \n",
    "\n",
    "donde\n",
    "$$\n",
    "[x]=\\begin{cases}\n",
    "       1, \\quad \\text{si $x$ es cierto} \\\\\n",
    "       0, \\quad \\text{en el resto}\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "La minimización de la entropía cruzada lleva $p_k$ cerca de 1 cuando $y = k$, que es lo que queremos.\n",
    "\n",
    "La hoja de ruta es:\n",
    "* Aplanar (flatten) las imágenes (28x28 -> 784) con `X_train.reshape((X_train.shape[0], -1))` para simplificar la implementación del modelo lineal.\n",
    "* Convertir `y_train` a vectores one-hot, 0 y 1, es lo necesario para la entropía cruzada.\n",
    "* Usar una variable `W` para todos los pesos (una columna $\\vec{w_k}$ por clase) y `b` para todos los sesgos.\n",
    "* Aspirar a ~0.93 de acierto en la validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train_flat = X_train.reshape((X_train.shape[0], -1))\n",
    "print(X_train_flat.shape)\n",
    "\n",
    "X_val_flat = X_val.reshape((X_val.shape[0], -1))\n",
    "print(X_val_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]] [5 0 4]\n"
     ]
    }
   ],
   "source": [
    "import keras  # solo se usará keras para keras.utils.to_categorical (one-hot)\n",
    "\n",
    "y_train_oh = keras.utils.to_categorical(y_train, 10)\n",
    "y_val_oh = keras.utils.to_categorical(y_val, 10)\n",
    "\n",
    "print(y_train_oh.shape)\n",
    "print(y_train_oh[:3], y_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vuelve a ejecutar esto si rehaces el gráfico\n",
    "s = reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-008eca92a5ca>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-008eca92a5ca>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    W = ### YOUR CODE HERE ### tf.get_variable(...) with shape[0] = 784\u001b[0m\n\u001b[0m                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Parametros del modelo: W and b\n",
    "W = ### Tu codigo aqui ### tf.get_variable(...) con shape[0] = 784\n",
    "b = ### Tu codigo aqui ### tf.get_variable(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrada de datos\n",
    "input_X = ### Tu codigo aqui ### tf.placeholder(...) para X flat con shape[0] = None para cualquier batch size\n",
    "input_y = ### Tu codigo aqui ### tf.placeholder(...) para one-hot, etiquetas verdaderas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "logits = ### Tu codigo aqui ### ecuaciones lineales (logits) input_X, dimension resultante [input_X.shape[0], 10]\n",
    "probs = ### Tu codigo aqui ### aplicar tf.nn.softmax a logits\n",
    "clases = ### Tu codigo aqui ### aplicar tf.argmax para encontrar el indice de la clase con mas probabilidad\n",
    "\n",
    "# La perdida (loss) debe ser un escalar: la media de la perdida sobre todos los objetos con tf.reduce_mean().\n",
    "# Usar tf.nn.softmax_cross_entropy_with_logits en one-hot input_y, y sobre los logits.\n",
    "# Es identico a calcular la entropia cruzada (perdida) sobre las probabilidades\n",
    "perdida = ### Tu codigo aqui ### perdida (cross-entropy loss)\n",
    "\n",
    "# Usar por defecto tf.train.AdamOptimizer para obtener un paso en SGD\n",
    "paso = ### Tu codigo aqui ### optimizador que minimiza la perdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'step' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2f3bd18d7b49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mbatch_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_start\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_flat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# data is already shuffled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         _, batch_loss = s.run([step, loss], {input_X: X_train_flat[batch_start:batch_start+BATCH_SIZE], \n\u001b[0m\u001b[1;32m     14\u001b[0m                                              input_y: y_train_oh[batch_start:batch_start+BATCH_SIZE]})\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# collect batch losses, this is almost free as we need a forward pass for backprop anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'step' is not defined"
     ]
    }
   ],
   "source": [
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "EPOCAS = 40\n",
    "\n",
    "# for logging the progress right here in Jupyter (for those who don't have TensorBoard)\n",
    "simpleTrainingCurves = matplotlib_utils.SimpleTrainingCurves(\"cross-entropy\", \"accuracy\")\n",
    "\n",
    "for epoca in range(EPOCAS):  # we finish an epoch when we've looked at all training samples\n",
    "    \n",
    "    batch_losses = []\n",
    "    for batch_start in range(0, X_train_flat.shape[0], BATCH_SIZE):  # data is already shuffled\n",
    "        _, batch_loss = s.run([paso, perdida], {input_X: X_train_flat[batch_start:batch_start+BATCH_SIZE], \n",
    "                                                input_y: y_train_oh[batch_start:batch_start+BATCH_SIZE]})\n",
    "        # collect batch losses, this is almost free as we need a forward pass for backprop anyway\n",
    "        batch_losses.append(batch_loss)\n",
    "\n",
    "    train_loss = np.mean(batch_losses)\n",
    "    val_loss = s.run(perdida, {input_X: X_val_flat, input_y: y_val_oh})  # this part is usually small\n",
    "    train_accuracy = accuracy_score(y_train, s.run(clases, {input_X: X_train_flat}))  # this is slow and usually skipped\n",
    "    valid_accuracy = accuracy_score(y_val, s.run(clases, {input_X: X_val_flat}))  \n",
    "    simpleTrainingCurves.add(train_loss, val_loss, train_accuracy, valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding more layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a couple of hidden layers and see how that improves our validation accuracy!\n",
    "\n",
    "Rememeber that we need non-linearities for hidden layers (e.g. `tf.sigmoid`)!\n",
    "\n",
    "Now add 1 or more hidden layers to the code above and restart training.\n",
    "You're aiming for ~0.98 validation accuracy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
