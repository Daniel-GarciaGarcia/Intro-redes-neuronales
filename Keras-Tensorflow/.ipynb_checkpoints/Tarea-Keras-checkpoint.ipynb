{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "* Tensorflow es una herramienta potente y flexible, pero programar grandes redes con Tensorflow puede ser tedioso.\n",
    "* Hay muchos paquetes de aprendizaje profundo que funcionan sobre Tensorflow, como Slim, TFLearn, Sonnet, Keras.\n",
    "* La elección depende del gusto del desarrollador y de la tarea.\n",
    "* Nosotros usaremos Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9591d7bf5e204948832fadfddf8d4370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=87910968), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e772f684b1104723ab210dec7f09cad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=170498071), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474e01934f5540dc9a7b7577bfd08e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11490434), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "realpath: '../readonly/keras/datasets/*': No existe el archivo o el directorio\n",
      "ln: fallo al crear el enlace simbólico './datasets': El archivo ya existe\n",
      "realpath: '../readonly/keras/models/*': No existe el archivo o el directorio\n",
      "ln: fallo al crear el enlace simbólico './models': El archivo ya existe\n"
     ]
    }
   ],
   "source": [
    "# se usan datasets y modelos precargardos en keras\n",
    "import download_utils\n",
    "download_utils.download_all_keras_resources(\"readonly/keras/models\", \"readonly/keras/datasets\")\n",
    "! mkdir -p ~/.keras/datasets\n",
    "! mkdir -p ~/.keras/models\n",
    "! ln -s $(realpath ../readonly/keras/datasets/*) ~/.keras/datasets/\n",
    "! ln -s $(realpath ../readonly/keras/models/*) ~/.keras/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from preprocessed_mnist import load_dataset\n",
    "import keras\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "y_train,y_val,y_test = map(keras.utils.np_utils.to_categorical,[y_train,y_val,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red con keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras_utils import reset_tf_session\n",
    "s = reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils.multi_gpu_utils import multi_gpu_model\n",
    "import keras.layers as ll\n",
    "\n",
    "modelo = Sequential(name=\"mlp\")   # perceptron multicapa\n",
    "\n",
    "modelo.add(ll.InputLayer([28, 28]))\n",
    "\n",
    "modelo.add(ll.Flatten())\n",
    "\n",
    "# cuerpo de la red\n",
    "modelo.add(ll.Dense(25))\n",
    "modelo.add(ll.Activation('linear'))\n",
    "\n",
    "modelo.add(ll.Dense(25))\n",
    "modelo.add(ll.Activation('linear'))\n",
    "\n",
    "# capa de salida: 10 neuronas para cada clase con sigmoide (softmax)\n",
    "modelo.add(ll.Dense(10, activation='softmax'))\n",
    "\n",
    "# categorical_crossentropy es la entropia cruzada de toda la vida\n",
    "# pero aplicada a vectores con one hot encoding\n",
    "modelo.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "#modelo_multi = keras.utils.multi_gpu_model(model, gpus=1, cpu_merge=True, cpu_relocation=False)\n",
    "#modelo_multi.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 25)                19625     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                260       \n",
      "=================================================================\n",
      "Total params: 20,535\n",
      "Trainable params: 20,535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interfaz del modelo\n",
    "\n",
    "Los modelos de Keras funcionan con la interfaz de __Scikit-learn__ usando fit/predict con algunas extensiones. Veamoslo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.2404 - acc: 0.9322 - val_loss: 0.2725 - val_acc: 0.9281\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.2388 - acc: 0.9329 - val_loss: 0.2803 - val_acc: 0.9260\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 0.2391 - acc: 0.9319 - val_loss: 0.2770 - val_acc: 0.9253\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 0.2385 - acc: 0.9321 - val_loss: 0.2765 - val_acc: 0.9256\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.2382 - acc: 0.9330 - val_loss: 0.2835 - val_acc: 0.9238\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 0.2378 - acc: 0.9318 - val_loss: 0.2732 - val_acc: 0.9273\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 0.2368 - acc: 0.9332 - val_loss: 0.2810 - val_acc: 0.9252\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.2373 - acc: 0.9329 - val_loss: 0.2783 - val_acc: 0.9275\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2373 - acc: 0.9330 - val_loss: 0.2761 - val_acc: 0.9281\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2368 - acc: 0.9327 - val_loss: 0.2746 - val_acc: 0.9283\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.2362 - acc: 0.9329 - val_loss: 0.2766 - val_acc: 0.9289\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.2354 - acc: 0.9330 - val_loss: 0.2828 - val_acc: 0.9251\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.2354 - acc: 0.9334 - val_loss: 0.2781 - val_acc: 0.9260\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 0.2363 - acc: 0.9336 - val_loss: 0.2782 - val_acc: 0.9275\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.2357 - acc: 0.9327 - val_loss: 0.2888 - val_acc: 0.9239\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.2351 - acc: 0.9326 - val_loss: 0.2870 - val_acc: 0.9239\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2350 - acc: 0.9329 - val_loss: 0.2793 - val_acc: 0.9276\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.2347 - acc: 0.9340 - val_loss: 0.2742 - val_acc: 0.9289\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2345 - acc: 0.9331 - val_loss: 0.2874 - val_acc: 0.9253\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.2346 - acc: 0.9333 - val_loss: 0.2794 - val_acc: 0.9266\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.2354 - acc: 0.9330 - val_loss: 0.2776 - val_acc: 0.9268\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.2330 - acc: 0.9333 - val_loss: 0.2778 - val_acc: 0.9286\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.2351 - acc: 0.9330 - val_loss: 0.2839 - val_acc: 0.9241\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.2337 - acc: 0.9345 - val_loss: 0.2856 - val_acc: 0.9247\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.2339 - acc: 0.9337 - val_loss: 0.2776 - val_acc: 0.9281\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2333 - acc: 0.9330 - val_loss: 0.2801 - val_acc: 0.9280\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.2329 - acc: 0.9332 - val_loss: 0.2874 - val_acc: 0.9259\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.2332 - acc: 0.9328 - val_loss: 0.2780 - val_acc: 0.9279\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2333 - acc: 0.9338 - val_loss: 0.2834 - val_acc: 0.9261\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2333 - acc: 0.9338 - val_loss: 0.2863 - val_acc: 0.9258\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.2328 - acc: 0.9339 - val_loss: 0.2773 - val_acc: 0.9285\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.2321 - acc: 0.9342 - val_loss: 0.2807 - val_acc: 0.9271\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.2318 - acc: 0.9340 - val_loss: 0.2859 - val_acc: 0.9258\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.2329 - acc: 0.9339 - val_loss: 0.2881 - val_acc: 0.9237\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.2309 - acc: 0.9335 - val_loss: 0.2883 - val_acc: 0.9244\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.2317 - acc: 0.9340 - val_loss: 0.2889 - val_acc: 0.9227\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.2320 - acc: 0.9342 - val_loss: 0.2832 - val_acc: 0.9266\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2310 - acc: 0.9338 - val_loss: 0.2782 - val_acc: 0.9290\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.2312 - acc: 0.9347 - val_loss: 0.2859 - val_acc: 0.9265\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2312 - acc: 0.9334 - val_loss: 0.2805 - val_acc: 0.9275\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.2315 - acc: 0.9342 - val_loss: 0.2814 - val_acc: 0.9262\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.2309 - acc: 0.9341 - val_loss: 0.2810 - val_acc: 0.9266\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 0.2306 - acc: 0.9350 - val_loss: 0.2756 - val_acc: 0.9287\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.2306 - acc: 0.9345 - val_loss: 0.2897 - val_acc: 0.9221\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.2302 - acc: 0.9351 - val_loss: 0.2838 - val_acc: 0.9251\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.2299 - acc: 0.9346 - val_loss: 0.2801 - val_acc: 0.9264\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 0.2314 - acc: 0.9340 - val_loss: 0.2839 - val_acc: 0.9258\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 0.2300 - acc: 0.9352 - val_loss: 0.2862 - val_acc: 0.9253\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.2298 - acc: 0.9342 - val_loss: 0.2786 - val_acc: 0.9286\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 0.2296 - acc: 0.9349 - val_loss: 0.2809 - val_acc: 0.9266\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 11s 210us/step - loss: 0.2295 - acc: 0.9346 - val_loss: 0.2911 - val_acc: 0.9249\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 0.2311 - acc: 0.9350 - val_loss: 0.2853 - val_acc: 0.9244\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.2300 - acc: 0.9339 - val_loss: 0.2849 - val_acc: 0.9249\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 0.2302 - acc: 0.9351 - val_loss: 0.2814 - val_acc: 0.9247\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 10s 210us/step - loss: 0.2293 - acc: 0.9342 - val_loss: 0.2840 - val_acc: 0.9254\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.2285 - acc: 0.9350 - val_loss: 0.2878 - val_acc: 0.9237\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.2295 - acc: 0.9351 - val_loss: 0.2920 - val_acc: 0.9235\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 0.2285 - acc: 0.9353 - val_loss: 0.2915 - val_acc: 0.9240\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.2290 - acc: 0.9345 - val_loss: 0.2851 - val_acc: 0.9244\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 0.2282 - acc: 0.9342 - val_loss: 0.2957 - val_acc: 0.9198\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.2286 - acc: 0.9340 - val_loss: 0.2807 - val_acc: 0.9282\n",
      "Epoch 62/100\n",
      " 1088/50000 [..............................] - ETA: 7s - loss: 0.2092 - acc: 0.9384"
     ]
    }
   ],
   "source": [
    "# Entrena\n",
    "modelo.fit(X_train, y_train,\n",
    "                validation_data=(X_val, y_val), epochs=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estima la probabilidades P(y|x)\n",
    "modelo.predict_proba(X_val[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda los pesos de entrenamiento\n",
    "model.save(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPerdida, Acierto = \", model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UUUps!\n",
    "Hasta aqui, nuestro modelo es muy ineficiente. Hay algo erróneo, adivina qué."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testeo del score...\n",
    "test_predicciones = modelo.predict_proba(X_test).argmax(axis=-1)\n",
    "test_respuestas = y_test.argmax(axis=-1)\n",
    "\n",
    "test_acierto = np.mean(test_predicciones==test_respuestas)\n",
    "\n",
    "print(\"\\nTesteo acierto: {} %\".format(test_acierto*100))\n",
    "\n",
    "assert test_acierto>=0.92,\"¡La regresión logística lo puede hacer mejor!\"\n",
    "assert test_acierto>=0.975,\"¡Tu red lo puede hacer mejor!\"\n",
    "print(\"¡Gran trabajo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras + tensorboard\n",
    "\n",
    "Remember the interactive graphs from Tensorboard one notebook ago? \n",
    "\n",
    "Thing is, Keras can use tensorboard to show you a lot of useful information about the learning progress. Just take a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r /tmp/tboard/**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "          epochs=10,\n",
    "          callbacks=[TensorBoard(\"/tmp/tboard\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips & tricks\n",
    "\n",
    "Here are some tips on what you could do. Don't worry, to reach the passing threshold you don't need to try all the ideas listed here, feel free to stop once you reach the 0.975 accuracy mark.\n",
    "\n",
    " * __Network size__\n",
    "   * More neurons, \n",
    "   * More layers, ([docs](https://keras.io/))\n",
    "\n",
    "   * Nonlinearities in the hidden layers\n",
    "     * tanh, relu, leaky relu, etc\n",
    "   * Larger networks may take more epochs to train, so don't discard your net just because it could didn't beat the baseline in 5 epochs.\n",
    "\n",
    "\n",
    " * __Early Stopping__\n",
    "   * Training for 100 epochs regardless of anything is probably a bad idea.\n",
    "   * Some networks converge over 5 epochs, others - over 500.\n",
    "   * Way to go: stop when validation score is 10 iterations past maximum\n",
    "     \n",
    "\n",
    " * __Faster optimization__\n",
    "   * rmsprop, nesterov_momentum, adam, adagrad and so on.\n",
    "     * Converge faster and sometimes reach better optima\n",
    "     * It might make sense to tweak learning rate/momentum, other learning parameters, batch size and number of epochs\n",
    "\n",
    "\n",
    " * __Regularize__ to prevent overfitting\n",
    "   * Add some L2 weight norm to the loss function, theano will do the rest\n",
    "     * Can be done manually or via - https://keras.io/regularizers/\n",
    "   \n",
    "   \n",
    " * __Data augmemntation__ - getting 5x as large dataset for free is a great deal\n",
    "   * https://keras.io/preprocessing/image/\n",
    "   * Zoom-in+slice = move\n",
    "   * Rotate+zoom(to remove black stripes)\n",
    "   * any other perturbations\n",
    "   * Simple way to do that (if you have PIL/Image): \n",
    "     * ```from scipy.misc import imrotate,imresize```\n",
    "     * and a few slicing\n",
    "   * Stay realistic. There's usually no point in flipping dogs upside down as that is not the way you usually see them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
