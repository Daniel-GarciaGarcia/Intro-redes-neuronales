{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Profundizando en Tensorflow\n",
    "\n",
    "Aqui vamos a estudiar las herramientas que se usaran para construir modelos de deep learning, esto es [Tensorflow](https://www.tensorflow.org/).\n",
    "\n",
    "En primer lugar, instalar Tensorflow con pip:\n",
    "* `pip install tensorflow` , solo TF en cpu tanto en Linux comom en Mac OS\n",
    "* Si quieres soporte para GPU mira esta pagina: [instalacion TF](https://www.tensorflow.org/install/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutando este notebook localmente, el acceso a TensorBoard seria en http://127.0.0.1:7007/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching processes belonging to you were found\r\n"
     ]
    }
   ],
   "source": [
    "! killall tensorboard\n",
    "import os\n",
    "os.system('tensorboard --logdir=/tmp/tboard --port=7007 &');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/data/Intro-redes-neuronales/Keras-Tensorflow/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/data/Intro-redes-neuronales/Keras-Tensorflow/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/data/Intro-redes-neuronales/Keras-Tensorflow/keras_utils.py:77: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "from keras_utils import reset_tf_session\n",
    "s = reset_tf_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empezando\n",
    "Para empezar vamos a implementar una funcion que calcule la suma de los cuadrados de los numeros de 0 a N-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def suma_cuad(N):\n",
    "    return np.sum(np.arange(N)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 718 µs, sys: 672 µs, total: 1.39 ms\n",
      "Wall time: 814 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "333328333350000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "suma_cuad(10**5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensoflow \n",
    "\n",
    "Hacemos exactamente lo mismo con Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un parametro entero\n",
    "N = tf.placeholder('int64', name='entrada_a_la_funcion')\n",
    "\n",
    "# Produce el mimso resultado\n",
    "res = tf.reduce_sum(tf.range(N)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum:0' shape=() dtype=int64>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.12 ms, sys: 1.3 ms, total: 4.42 ms\n",
      "Wall time: 2.61 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "333328333350000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "res.eval({N: 10**5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "escritor = tf.summary.FileWriter('/tmp/tboard', graph=s.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Como funciona?\n",
    "1. Se definen unos marcadores (placeholders) donde se envian las entradas (inputs)\n",
    "2. Se hace un grafo simbolico (symbolic graph): una receta para transformaciones matematicas de esos marcadores \n",
    "3. Se calculan las salidas del grafo con valores para cada marcador\n",
    "  * `salida.eval({marcador:valor})`\n",
    "  * `s.run(salida, {marcador:valor})`\n",
    "\n",
    "Asi que existen dos entidades principales: el marcador (placeholder) y la transformacion matematica\n",
    "* Ambos pueden ser numeros, vectores, matrices, tensores, etc...\n",
    "* Ambos pueden ser int32/64, floats, booleanos (uint8)...\n",
    "* Se pueden definir nuevas transformaciones como operaciones arbitrarias en los marcadores y otras transformaciones\n",
    " * `tf.reduce_sum(tf.arange(N)**2)` son 3 transformaciones secuenciales del marcador `N`\n",
    " * Hay una version simbolica en Tensorflow para cada funcion de numpy \n",
    "   * `a+b, a/b, a**b, ...` se comporta igual que en numpy\n",
    "   * `np.mean` -> `tf.reduce_mean`\n",
    "   * `np.arange` -> `tf.range`\n",
    "   * `np.cumsum` -> `tf.cumsum`\n",
    "   * Si no encuentras la funcion que necesitas, puedes mirar la [documentacion](https://www.tensorflow.org/api_docs/python).\n",
    "   \n",
    "`tf.contrib` tiene muchas caracteristicas de alto nivel, echale un ojo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Ejemplo_marcadores'):\n",
    "    # El marcador por defecto (placeholder) puede ser arbitrariamente float32\n",
    "    # escalar, vector, matrix, etc...\n",
    "    entrada_arbitraria = tf.placeholder('float32')\n",
    "\n",
    "    # Vector de entrada de longitud arbitraria\n",
    "    vector_entrada = tf.placeholder('float32', shape=(None,))\n",
    "\n",
    "    # Vector de entrada que tienec 10 elementos de tipo entero\n",
    "    vector_fijo = tf.placeholder('int32', shape=(10,))\n",
    "\n",
    "    # Matriz con numero de filas arbitrario y 15 columnas\n",
    "    # (e.g. una muestra de tu tabla de datos)\n",
    "    matriz_entrada = tf.placeholder('float32', shape=(None, 15))\n",
    "    \n",
    "    # Generalmente se usa None cuando no se necesita especificar la dimension\n",
    "    entrada1 = tf.placeholder('float64', shape=(None, 100, None))\n",
    "    entrada2 = tf.placeholder('int32', shape=(None, None, 3, 224, 224))\n",
    "\n",
    "    # Multiplicacion elemento a elemento\n",
    "    vector_doble = vector_entrada*2\n",
    "\n",
    "    # Coseno\n",
    "    coseno = tf.cos(vector_entrada)\n",
    "\n",
    "    # Diferencia entre el vector al cuadrado y el propio vector mas uno \n",
    "    cuadrado_vector = vector_entrada**2 - vector_entrada + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_vector =  tf.placeholder('float32', shape=(None,), name=\"VECTOR_1\")\n",
    "mi_vector2 = tf.placeholder('float32', shape=(None,))\n",
    "mi_transformacion = mi_vector * mi_vector2 / (tf.sin(mi_vector) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"truediv:0\", shape=(?,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(mi_transformacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.       , 1.6291324, 2.0950115, 2.6289961, 0.       ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = np.arange(5).astype('float32')\n",
    "print(dummy)\n",
    "mi_transformacion.eval({mi_vector:dummy, mi_vector2:dummy[::-1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "escritor.add_graph(mi_transformacion.graph)\n",
    "escritor.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard permite escribir escalares, imagenes, audio, histogramas. Puedes leer mas sobre tensorboard [aqui](https://www.tensorflow.org/get_started/graph_viz)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumen\n",
    "* Tensorflow esta basado en la computacion de grafos\n",
    "* Los grafos constan de marcadores (placeholders) y transformaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error cuadratico medio\n",
    "\n",
    "La tarea es implementar el error cuadratico medio en Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.arange(5)\n",
    "y_pred = np.arange(5)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16,  4,  0,  4, 16])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y - y_pred) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('MSE'):\n",
    "    y_true = tf.placeholder('float32', shape=(None,), name='y_true')\n",
    "    y_predicho = tf.placeholder('float32', shape=(None,), name='y_predicho')\n",
    "    mse = tf.reduce_mean((y_true - y_predicho) ** 2)\n",
    "def c_mse(vector1, vector2):\n",
    "    return mse.eval({y_true: vector1, y_predicho: vector2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "escritor.add_graph(mse.graph)\n",
    "escritor.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testeo local de la implementacion del MSE\n",
    "import sklearn.metrics\n",
    "for n in [1, 5, 10, 10**3]:\n",
    "    elems = [np.arange(n), np.arange(n, 0, -1), np.zeros(n),\n",
    "             np.ones(n), np.random.random(n), np.random.randint(100, size=n)]\n",
    "    for e in elems:\n",
    "        for e_2 in elems:\n",
    "            true_mse = np.array(sklearn.metrics.mean_squared_error(e, e_2))\n",
    "            mi_mse = c_mse(e, e_2)\n",
    "            if not np.allclose(true_mse, mi_mse):\n",
    "                print('mse({},{})'.format(e, e_2))\n",
    "                print('deberia ser: {}, pero la funcion devuelve {}'.format(true_mse, mi_mse))\n",
    "                raise ValueError('Resultado incorrecto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables\n",
    "\n",
    "The inputs and transformations have no value outside function call. This isn't too comfortable if you want your model to have parameters (e.g. network weights) that are always present, but can change their value over time.\n",
    "\n",
    "Tensorflow solves this with `tf.Variable` objects.\n",
    "* You can assign variable a value at any time in your graph\n",
    "* Unlike placeholders, there's no need to explicitly pass values to variables when `s.run(...)`-ing\n",
    "* You can use variables the same way you use transformations \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a shared variable\n",
    "shared_vector_1 = tf.Variable(initial_value=np.ones(5),\n",
    "                              name=\"example_variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variable(s) with initial values\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "# Evaluating shared variable (outside symbolicd graph)\n",
    "print(\"Initial value\", s.run(shared_vector_1))\n",
    "\n",
    "# Within symbolic graph you use them just\n",
    "# as any other inout or transformation, not \"get value\" needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a new value\n",
    "s.run(shared_vector_1.assign(np.arange(5)))\n",
    "\n",
    "# Getting that new value\n",
    "print(\"New value\", s.run(shared_vector_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.gradients - why graphs matter\n",
    "* Tensorflow can compute derivatives and gradients automatically using the computation graph\n",
    "* True to its name it can manage matrix derivatives\n",
    "* Gradients are computed as a product of elementary derivatives via the chain rule:\n",
    "\n",
    "$$ {\\partial f(g(x)) \\over \\partial x} = {\\partial f(g(x)) \\over \\partial g(x)}\\cdot {\\partial g(x) \\over \\partial x} $$\n",
    "\n",
    "It can get you the derivative of any graph as long as it knows how to differentiate elementary operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scalar = tf.placeholder('float32')\n",
    "\n",
    "scalar_squared = my_scalar**2\n",
    "\n",
    "# A derivative of scalar_squared by my_scalar\n",
    "derivative = tf.gradients(scalar_squared, [my_scalar, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = np.linspace(-3, 3)\n",
    "x_squared, x_squared_der = s.run([scalar_squared, derivative[0]],\n",
    "                                 {my_scalar:x})\n",
    "\n",
    "plt.plot(x, x_squared,label=\"$x^2$\")\n",
    "plt.plot(x, x_squared_der, label=r\"$\\frac{dx^2}{dx}$\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why that rocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vector = tf.placeholder('float32', [None])\n",
    "# Compute the gradient of the next weird function over my_scalar and my_vector\n",
    "# Warning! Trying to understand the meaning of that function may result in permanent brain damage\n",
    "weird_psychotic_function = tf.reduce_mean(\n",
    "    (my_vector+my_scalar)**(1+tf.nn.moments(my_vector,[0])[1]) + \n",
    "    1./ tf.atan(my_scalar))/(my_scalar**2 + 1) + 0.01*tf.sin(\n",
    "    2*my_scalar**1.5)*(tf.reduce_sum(my_vector)* my_scalar**2\n",
    "                      )*tf.exp((my_scalar-4)**2)/(\n",
    "    1+tf.exp((my_scalar-4)**2))*(1.-(tf.exp(-(my_scalar-4)**2)\n",
    "                                    )/(1+tf.exp(-(my_scalar-4)**2)))**2\n",
    "\n",
    "der_by_scalar = tf.gradients(weird_psychotic_function, my_scalar)\n",
    "der_by_vector = tf.gradients(weird_psychotic_function, my_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the derivative\n",
    "scalar_space = np.linspace(1, 7, 100)\n",
    "\n",
    "y = [s.run(weird_psychotic_function, {my_scalar:x, my_vector:[1, 2, 3]})\n",
    "     for x in scalar_space]\n",
    "\n",
    "plt.plot(scalar_space, y, label='function')\n",
    "\n",
    "y_der_by_scalar = [s.run(der_by_scalar,\n",
    "                         {my_scalar:x, my_vector:[1, 2, 3]})\n",
    "                   for x in scalar_space]\n",
    "\n",
    "plt.plot(scalar_space, y_der_by_scalar, label='derivative')\n",
    "plt.grid()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Almost done - optimizers\n",
    "\n",
    "While you can perform gradient descent by hand with automatic grads from above, tensorflow also has some optimization methods implemented for you. Recall momentum & rmsprop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_guess = tf.Variable(np.zeros(2, dtype='float32'))\n",
    "y_true = tf.range(1, 3, dtype='float32')\n",
    "loss = tf.reduce_mean((y_guess - y_true + tf.random_normal([2]))**2) \n",
    "#loss = tf.reduce_mean((y_guess - y_true)**2) \n",
    "optimizer = tf.train.MomentumOptimizer(0.01, 0.5).minimize(\n",
    "    loss, var_list=y_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation, rc\n",
    "import matplotlib_utils\n",
    "from IPython.display import HTML, display_html\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "y_true_value = s.run(y_true)\n",
    "level_x = np.arange(0, 2, 0.02)\n",
    "level_y = np.arange(0, 3, 0.02)\n",
    "X, Y = np.meshgrid(level_x, level_y)\n",
    "Z = (X - y_true_value[0])**2 + (Y - y_true_value[1])**2\n",
    "ax.set_xlim(-0.02, 2)\n",
    "ax.set_ylim(-0.02, 3)\n",
    "s.run(tf.global_variables_initializer())\n",
    "ax.scatter(*s.run(y_true), c='red')\n",
    "contour = ax.contour(X, Y, Z, 10)\n",
    "ax.clabel(contour, inline=1, fontsize=10)\n",
    "line, = ax.plot([], [], lw=2)\n",
    "\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    return (line,)\n",
    "\n",
    "guesses = [s.run(y_guess)]\n",
    "\n",
    "def animate(i):\n",
    "    s.run(optimizer)\n",
    "    guesses.append(s.run(y_guess))\n",
    "    line.set_data(*zip(*guesses))\n",
    "    return (line,)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=400, interval=20, blit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['animation.ffmpeg_path'] = '/usr/bin/ffmpeg'\n",
    "try:\n",
    "    display_html(HTML(anim.to_html5_video()))\n",
    "# In case the build-in renderers are unaviable, fall back to\n",
    "# a custom one, that doesn't require external libraries\n",
    "except (RuntimeError, KeyError):\n",
    "    anim.save(None, writer=matplotlib_utils.SimpleMovieWriter(0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "Your assignment is to implement the logistic regression\n",
    "\n",
    "Plan:\n",
    "* Use a shared variable for weights\n",
    "* Use a matrix placeholder for `X`\n",
    " \n",
    "We shall train on a two-class MNIST dataset\n",
    "* please note that target `y` are `{0,1}` and not `{-1,1}` as in some formulae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "mnist = load_digits(2)\n",
    "\n",
    "X, y = mnist.data, mnist.target\n",
    "\n",
    "print(\"y [shape - %s]:\" % (str(y.shape)), y[:10])\n",
    "print(\"X [shape - %s]:\" % (str(X.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X:\\n',X[:3,:10])\n",
    "print('y:\\n',y[:10])\n",
    "plt.imshow(X[7].reshape([8,8]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's your turn now!\n",
    "Just a small reminder of the relevant math:\n",
    "\n",
    "$$\n",
    "P(y=1|X) = \\sigma(X \\cdot W + b)\n",
    "$$\n",
    "$$\n",
    "\\text{loss} = -\\log\\left(P\\left(y_\\text{predicted} = 1\\right)\\right)\\cdot y_\\text{true} - \\log\\left(1 - P\\left(y_\\text{predicted} = 1\\right)\\right)\\cdot\\left(1 - y_\\text{true}\\right)\n",
    "$$\n",
    "\n",
    "$\\sigma(x)$ is available via `tf.nn.sigmoid` and matrix multiplication via `tf.matmul`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your code goes here.__ For the training and testing scaffolding to work, please stick to the names in comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters - weights and bias\n",
    "# weights = tf.Variable(...) shape should be (X.shape[1], 1)\n",
    "# b = tf.Variable(...)\n",
    "\n",
    "weights = tf.Variable(np.zeros((X.shape[1], 1), dtype='float32'))\n",
    "b = tf.Variable(np.zeros(None), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders for the input data\n",
    "# input_X = tf.placeholder(...)\n",
    "# input_y = tf.placeholder(...)\n",
    "\n",
    "input_X = tf.placeholder(\"float32\", shape=(None, X.shape[1]), name=\"input_X\")\n",
    "input_y = tf.placeholder(\"float32\", shape=(None,), name=\"input_y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model code\n",
    "\n",
    "# Compute a vector of predictions, resulting shape should be [input_X.shape[0],]\n",
    "# This is 1D, if you have extra dimensions, you can  get rid of them with tf.squeeze .\n",
    "# Don't forget the sigmoid.\n",
    "# predicted_y = <predicted probabilities for input_X>\n",
    "\n",
    "predicted_y = tf.squeeze(tf.sigmoid(input_X @ weights + b))\n",
    "\n",
    "# Loss. Should be a scalar number - average loss over all the objects\n",
    "# tf.reduce_mean is your friend here\n",
    "# loss = <logistic loss (scalar, mean over sample)>\n",
    "loss = tf.reduce_mean(-tf.log(predicted_y) * input_y - tf.log(1 - predicted_y) * (1 - input_y))\n",
    "\n",
    "# See above for an example. tf.train.*Optimizer\n",
    "# optimizer = <optimizer that minimizes loss>\n",
    "optimizer = tf.train.MomentumOptimizer(0.01, 0.5).minimize(loss, var_list=[weights, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A test to help with the debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_weights = 1e-3 * np.fromiter(map(lambda x:\n",
    "        s.run(weird_psychotic_function, {my_scalar:x, my_vector:[1, 0.1, 2]}),\n",
    "                                   0.15 * np.arange(1, X.shape[1] + 1)),\n",
    "                                   count=X.shape[1], dtype=np.float32)[:, np.newaxis]\n",
    "\n",
    "# Compute predictions for given weights and bias\n",
    "prediction_validation = s.run(\n",
    "    predicted_y, {\n",
    "    input_X: X,\n",
    "    weights: validation_weights,\n",
    "    b: 1e-1})\n",
    "\n",
    "#prediction_validation = prediction_validation.flatten()\n",
    "\n",
    "# Load the reference values for the predictions\n",
    "validation_true_values = np.loadtxt(\"predicciones_de_validacion.txt\")\n",
    "\n",
    "assert prediction_validation.shape == (X.shape[0],),\\\n",
    "       \"Predictions must be a 1D array with length equal to the number \" \\\n",
    "       \"of examples in input_X\"\n",
    "assert np.allclose(validation_true_values, prediction_validation)\n",
    "loss_validation = s.run(\n",
    "        loss, {\n",
    "            input_X: X[:100],\n",
    "            input_y: y[-100:],\n",
    "            weights: validation_weights+1.21e-3,\n",
    "            b: -1e-1})\n",
    "assert np.allclose(loss_validation, 0.728689)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "s.run(tf.global_variables_initializer())\n",
    "for i in range(5):\n",
    "    s.run(optimizer, {input_X: X_train, input_y: y_train})\n",
    "    loss_i = s.run(loss, {input_X: X_train, input_y: y_train})\n",
    "    print(\"loss at iter %i:%.4f\" % (i, loss_i))\n",
    "    print(\"train auc:\", roc_auc_score(y_train, s.run(predicted_y, {input_X:X_train})))\n",
    "    print(\"test auc:\", roc_auc_score(y_test, s.run(predicted_y, {input_X:X_test})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# era submision aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weights = 1e-3 * np.fromiter(map(lambda x:\n",
    "    s.run(weird_psychotic_function, {my_scalar:x, my_vector:[1, 2, 3]}),\n",
    "                               0.1 * np.arange(1, X.shape[1] + 1)),\n",
    "                               count=X.shape[1], dtype=np.float32)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, test prediction and loss computation. This part doesn't require a fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = s.run(\n",
    "    predicted_y, {\n",
    "    input_X: X,\n",
    "    weights: test_weights,\n",
    "    b: 1e-1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert prediction_test.shape == (X.shape[0],),\\\n",
    "       \"Predictions must be a 1D array with length equal to the number \" \\\n",
    "       \"of examples in X_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_test = s.run(\n",
    "    loss, {\n",
    "        input_X: X[:100],\n",
    "        input_y: y[-100:],\n",
    "        weights: test_weights+1.21e-3,\n",
    "        b: -1e-1})\n",
    "# Yes, the X/y indices mistmach is intentional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
